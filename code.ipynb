{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e49c5e-1b2a-49d8-9d65-20ba40c2b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BinaryLogisticRegression:\n",
    "    def __init__(self, n_features, batch_size, conv_threshold):\n",
    "        self.n_features = n_features\n",
    "        self.weights = np.zeros(n_features + 1)  # extra element for bias\n",
    "        self.alpha = 0.01\n",
    "        self.batch_size = batch_size\n",
    "        self.conv_threshold = conv_threshold\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        # intializing values\n",
    "        converge = False\n",
    "        epochs = 0\n",
    "        n_examples = X.shape[0]\n",
    "\n",
    "        while not converge:\n",
    "            # update # of epochs\n",
    "            epochs += 1\n",
    "            # acquire indices for shuffling of X and Y\n",
    "            indices = np.arange(n_examples)\n",
    "            np.random.shuffle(indices)\n",
    "            X = X[indices]\n",
    "            Y = Y[indices]\n",
    "            # calc last epoch loss\n",
    "            last_epoch_loss = self.loss(X, Y)\n",
    "            # for the # of batches\n",
    "            for i in range(0, n_examples, self.batch_size):\n",
    "                X_batch = X[i:i + self.batch_size]\n",
    "                Y_batch = Y[i:i + self.batch_size]\n",
    "                # reinitialize gradient to be 0s\n",
    "                grad = np.zeros(self.weights.shape)\n",
    "                # for each pair in the batch\n",
    "                for x, y in zip(X_batch, Y_batch):\n",
    "                    prediction = self.sigmoid(np.dot(self.weights, x))\n",
    "                    # gradient calculation\n",
    "                    error = prediction - y\n",
    "                    grad += error * x\n",
    "                # update weights\n",
    "                self.weights -= (self.alpha * grad) / self.batch_size\n",
    "            epoch_loss = self.loss(X, Y)\n",
    "            if abs(epoch_loss - last_epoch_loss) < self.conv_threshold:\n",
    "                converge = True\n",
    "        return epochs\n",
    "\n",
    "    def loss(self, X, Y):\n",
    "        n_examples = X.shape[0]\n",
    "        total_loss = 0\n",
    "    \n",
    "        for i in range(n_examples):\n",
    "            linear_output = np.dot(self.weights, X[i])\n",
    "            y = 1 if Y[i] == 1 else -1  # Convert labels to {-1, 1}\n",
    "            # compute logistic loss\n",
    "            logistic_loss = np.log(1 + np.exp(-y * linear_output))\n",
    "            total_loss += logistic_loss\n",
    "    \n",
    "        return total_loss / n_examples\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # multiply X by weights of model\n",
    "        predictions = self.sigmoid(X @ self.weights)\n",
    "        return np.where(predictions >= 0.5, 1, 0)\n",
    "\n",
    "    def accuracy(self, X, Y):\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = np.mean(predictions == Y)\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546682e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllPairsLogisticRegression:\n",
    "    def __init__(self, n_classes, binary_classifier_class, n_features, batch_size, conv_threshold):\n",
    "        \"\"\"\n",
    "        Initialize the all-pairs logistic regression model.\n",
    "        @param n_classes: Number of classes in the dataset, an integer.\n",
    "        @param binary_classifier_class: Class for binary logistic regression, a class object.\n",
    "        @param n_features: Number of features in the dataset, an integer.\n",
    "        @param batch_size: Batch size for training the binary classifiers, an integer.\n",
    "        @param conv_threshold: Convergence threshold for training, a float.\n",
    "        @return: None\n",
    "        \"\"\"\n",
    "        self.n_classes = n_classes\n",
    "        self.classifiers = {} \n",
    "        self.n_features = n_features\n",
    "        self.batch_size = batch_size\n",
    "        self.conv_threshold = conv_threshold\n",
    "        self.binary_classifier_class = binary_classifier_class\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        \"\"\"\n",
    "        Train the all-pairs logistic regression model by training binary classifiers\n",
    "        for each pair of classes in the dataset.\n",
    "        @param X: Input features of the dataset, a numpy array of shape (n_samples, n_features).\n",
    "        @param Y: Labels of the dataset, a numpy array of shape (n_samples,).\n",
    "        @return: None\n",
    "        \"\"\"\n",
    "        for class_i in range(self.n_classes):\n",
    "            for class_j in range(class_i + 1, self.n_classes):\n",
    "                SX = []\n",
    "                SY = []\n",
    "                for t in range(len(Y)):\n",
    "                    if Y[t] == class_i:\n",
    "                        SX.append(X[t])\n",
    "                        SY.append(1)\n",
    "                    elif Y[t] == class_j:\n",
    "                        SX.append(X[t])\n",
    "                        SY.append(-1)\n",
    "                SX = np.array(SX)\n",
    "                SY = np.array(SY)\n",
    "                classifier = self.binary_classifier_class(\n",
    "                    n_features=self.n_features,\n",
    "                    batch_size=self.batch_size,\n",
    "                    conv_threshold=self.conv_threshold\n",
    "                )\n",
    "                classifier.train(SX, SY)\n",
    "                self.classifiers[(class_i, class_j)] = classifier\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels for the input data using the trained classifiers.\n",
    "        @param X: Input features to classify, a numpy array of shape (n_samples, n_features).\n",
    "        @return: Predicted class labels, a numpy array of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        votes = np.zeros((n_samples, self.n_classes), dtype=int)\n",
    "        for (class_i, class_j), classifier in self.classifiers.items():\n",
    "            predictions = classifier.predict(X)\n",
    "            votes[:, class_i] += (predictions == 1)\n",
    "            votes[:, class_j] += (predictions == 0)\n",
    "        return np.argmax(votes, axis=1)\n",
    "\n",
    "    def accuracy(self, X, Y):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of the model on the input data and labels.\n",
    "        @param X: Input features of the dataset, a numpy array of shape (n_samples, n_features).\n",
    "        @param Y: True labels of the dataset, a numpy array of shape (n_samples,).\n",
    "        @return: Accuracy of the model as a float between 0 and 1.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        correct_predictions = np.sum(predictions == Y)\n",
    "        return correct_predictions / len(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
